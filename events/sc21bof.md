# SC21 Conference Birds-of-a-Feather (BOF)

## HPC System Test: Towards Improving Availability and Portability of HPC Test Suites

### BOF Session Description

This session will build upon the knowledge we have gathered from centers including the IT Center for Science in Finland (CSC), Swiss National Supercomputing Centre (CSCS), Indiana University (IU), King Abdullah University of Science & Technology (KAUST), National Center for Supercomputing Applications (NCSA), National Energy Research Scientific Computing center (NERSC), Oak Ridge National Laboratory (ORNL), Los Alamos National Laboratory (LANL), and Lawrence Livermore National Laboratory (LLNL). From previous collaborations, we have learned that individual centers have specific sets of tools, both in-house developed and open source, that are used to launch and monitor tests during acceptance and regression testing. For example, KAUST and CSCS rely on ReFrame for regression testing, whereas ORNL, LANL, and LLNL use in-house developed tools that are now open source. The information collected about the tools featured can be found at: https://olcf.github.io/hpc-system-test-wg/ 
On the other hand, we also learned that there is significant overlap in the tests developed and executed at each center. With this fourth iteration of the HPC System Test BOF we aim to gain a better understanding of the tests available at each participating center and determine how we can leverage community efforts to augment and improve tests suites.  

Prior to the session, we will invite members of the newly formed HPC System Test working group to sign-up for lightning talks to share information about their current testing suites and their availability. During the session, we will first share a roadmap of the current state of test availability at four different HPC centers: LANL, KAUST, CSCS, and ORNL, followed by a working discussion on how to best distribute, utilize, and contribute to these test suites. Attendees will be invited to consider the following questions:
- Can we design a common template that can capture the information you would need to port a test to your system/facility?
- What are the top 3 areas at your center that currently have good test coverage? 
- What are the top 3 areas at your center that do not currently have good test coverage?
- How do you envision adapting testing at your center to support new types of non-traditional HPC workloads (e.g., containerized applications, dynamic cloud-like HPC environments)?
- Does your center currently support workloads on specialized hardware (e.g., FPGA, AI specialized HW)? If yes, what testing procedures do you use?

The material and discussions in the session will be beneficial to both users, system administrators, and center staff at research computing, industry, and academic institutions from small to leadership-class scales.

### When & Where

- *Date:* TBD by SC21.
- *Location:* Virtual via SC21 HUBB (link TBA)

### Agenda 

- Audience Survey
- Lightning talks  on “Test Suites Content and Availability”
  - First half will be presented by the session leaders representing 4 different institutions
  - At least 2 Lightning talks will be chosen from community submissions: 
    - Submit by **Oct 13, 2021 AOE** at https://tinyurl.com/sc21-hpctest-talk 
- Open Q&A with presenters
- Working session to discuss development of a common template
- Defining Next Steps

### Session leaders
- Bilel Hadri (King Abdullah University of Science and Technology)
- Francine Lapid (Los Alamos National Laboratory)
- Paul Ferrell (Los Alamos National Laboratory)
- Vasileios Karakasis (Swiss National Supercomputing Centre)
- Verónica G. Melesse Vergara (Oak Ridge National Laboratory) 

